{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Inverse Covariance Estimation\n",
    "\n",
    "**References:**\n",
    "1. S. Boyd and L. Vandenberghe. Chapter 7.1.1 in [*Convex Optimization.*](https://web.stanford.edu/~boyd/cvxbook/) Cambridge University Press, 2004.\n",
    "2. O. Bannerjee, L. E. Ghaoui, and A. d'Aspremont. [*Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data.*](http://www.jmlr.org/papers/volume9/banerjee08a/banerjee08a.pdf) Journal of Machine Learning Research, 9(1):485-516, 2008.\n",
    "3. J. Friedman, T. Hastie, and R. Tibshirani. [*Sparse Inverse Covariance Estimation with the Graphical Lasso.*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3019769/) Biostatistics, 9(3):432-441, 2008.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Suppose $z \\in \\mathbf{R}^q$ is a Gaussian random variable with mean zero and covariance matrix $\\Sigma$, where $\\Sigma^{-1}$ \n",
    "is known to be sparse. (This implies that many pairs of elements in $z$ are conditionally independent). We want to estimate the covariance matrix based on samples $z_1,\\ldots,z_p$ drawn independently from $N(0,\\Sigma)$.\n",
    "\n",
    "A good heuristic for estimating $\\Sigma$ is to solve the problem\n",
    "\n",
    "$$\\text{minimize}~ -\\log\\det(S) + \\text{tr}(SQ) + \\alpha\\|S\\|_1$$\n",
    "\n",
    "with respect to $S \\in \\mathbf{S}^q$ (the set of symmetric matrices), where $Q = \\frac{1}{p}\\sum_{l=1}^p z_lz_l^T$ is the sample covariance and $\\alpha > 0$ is a sparsity parameter. Here $\\log\\det$ is understood to be an extended real-valued function, so that $\\log\\det(S) = -\\infty$ whenever $S$ is not positive definite.\n",
    "\n",
    "If $S^*$ is the solution to this problem, we take our estimate of the covariance matrix to be $\\hat \\Sigma = (S^*)^{-1}$.\n",
    "\n",
    "## Reformulate Problem\n",
    "\n",
    "Let $x_i \\in \\mathbf{R}^{q(q+1)/2}$ be a vectorization of $S_i \\in \\mathbf{S}^q$ for $i = 1,2$. For instance, $x_i$ could be the lower triangular elements of $S_i$ taken in column order. The sparse inverse covariance estimation problem can be written in standard form by setting\n",
    "\n",
    "$$f_1(x_1) = -\\log\\det(S_1) + \\text{tr}(S_1Q), \\quad f_2(x_2) = \\alpha\\|S_2\\|_1,$$\n",
    "\n",
    "where it is implicit that $x_i$ is reshaped into $S_i$. Notice that we have grouped the $\\log\\det$ term with the matrix trace term. This is because $\\text{tr}(S_1Q)$ is an affine function, so we can apply the affine addition rule to evaluate $\\mathbf{prox}_{tf_1}$ using $\\mathbf{prox}_{t\\log\\det(\\cdot)}$. See Sections 2.2 and 6.7.5 of [N. Parikh and S. Boyd (2013)](https://web.stanford.edu/~boyd/papers/prox_algs.html).\n",
    "\n",
    "## Generate Data\n",
    "\n",
    "We generate $S$ randomly from the set of symmetric positive definite matrices with $q = 80$ and about 10% nonzero entries. Then, we compute $Q$ using $p = 1000$ IID samples drawn from $N(0,S^{-1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from sklearn.datasets import mark_sparse_spd_matrix\n",
    "from a2dr import a2dr\n",
    "from a2dr.proximal import *\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Problem data.\n",
    "q = 80\n",
    "p = 1000\n",
    "nnz_ratio = 0.1   # Fraction of nonzeros in S.\n",
    "\n",
    "# Create sparse symmetric PSD matrix S.\n",
    "S_true = sparse.csc_matrix(make_sparse_spd_matrix(q,1-nnz_ratio))\n",
    "\n",
    "# Create covariance matrix associated with S.\n",
    "Sigma = sparse.linalg.inv(S_true).todense()\n",
    "\n",
    "# Draw samples from the Gaussian distribution with covariance Sigma.\n",
    "z_sample = sp.linalg.sqrtm(Sigma).dot(np.random.randn(q,p))\n",
    "Q = np.cov(z_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Problem for Several $\\alpha$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate smallest alpha for which solution is trivially\n",
    "# the diagonal matrix (diag(Q) + alpha*I)^{-1}.\n",
    "# Reference: O. Bannerjee, L. E. Ghaoui, and A. d'Aspremont (2008).\n",
    "mask = np.ones(Q.shape, dtype=bool)\n",
    "np.fill_diagonal(mask, 0)\n",
    "alpha_max = np.max(np.abs(Q)[mask])\n",
    "\n",
    "# The alpha values for each attempt at generating S.\n",
    "alpha_ratios = np.array([1, 0.01, 0.001])\n",
    "alphas = alpha_ratios*alpha_max\n",
    "\n",
    "# Empty list of result matrices S.\n",
    "Ss = []\n",
    "\n",
    "# Solve for the problem for each value of alpha.\n",
    "for alpha in alphas:\n",
    "    # Convert problem to standard form.\n",
    "    prox_list = [lambda v, t: prox_neg_log_det(v.reshape((q,q), order='C'), t, lin_term=t*Q).ravel(order='C'), \n",
    "                 lambda v, t: prox_norm1(v, t*alpha)]\n",
    "    A_list = [sparse.eye(q*q), -sparse.eye(q*q)]\n",
    "    b = np.zeros(q*q)\n",
    "    \n",
    "    # Solve with A2DR.\n",
    "    a2dr_result = a2dr(prox_list, A_list, b)\n",
    "    a2dr_S = a2dr_result[\"x_vals\"][-1].reshape((q,q), order='C')\n",
    "    \n",
    "    # Threshold S element values to enforce exact zeroes.\n",
    "    S_thres = a2dr_S\n",
    "    S_thres[np.abs(S_thres) <= 1e-4] = 0\n",
    "    \n",
    "    # Store thresholded S for later visualization.\n",
    "    Ss += [S_thres]\n",
    "    \n",
    "    print(\"Solved optimization problem with alpha =\", alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Resulting Sparsity Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show plot inline in ipython.\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot properties.\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "# Create figure.\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Plot sparsity pattern for the true covariance matrix.\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.spy(S_true)\n",
    "plt.title('Inverse of true covariance matrix', fontsize=16)\n",
    "\n",
    "# Plot sparsity pattern for each result, corresponding to a specific alpha.\n",
    "for i in range(len(alphas)):\n",
    "    plt.subplot(2, 2, 2+i)\n",
    "    plt.spy(Ss[i])\n",
    "    plt.title('Estimated inv. cov. matrix, $\\\\alpha$={}'.format(alphas[i]), fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
